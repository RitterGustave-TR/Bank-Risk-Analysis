{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic regression is a machine learning model used to make predictions according to linear function of the input features. Can be used for both regression and classification but in this case we willbe using it as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "# MUTATE DATAFRAMES ACCORDING TO THE EXPLORATORY DATA ANALYSIS CODE\n",
    "\n",
    "#For data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#In order to show all columns available\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "#Sklearn imports\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "\n",
    "#Graphing libs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "apptrain = pd.read_csv('../Dataset/application_train.csv')\n",
    "apptest = pd.read_csv('../Dataset/application_test.csv')\n",
    "\n",
    "# Code that modifies dataframes\n",
    "apptrain['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "apptest['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "apptrain['DAYS_BIRTH'] = abs(apptrain['DAYS_BIRTH'])\n",
    "apptest['DAYS_BIRTH'] = abs(apptrain['DAYS_BIRTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (307511, 243)\n",
      "Training features shape: (48744, 239)\n",
      "3 columns were label encoded\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding and dataframe alignment\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through columns\n",
    "for col in apptrain:\n",
    "    if apptrain[col].dtype == \"object\":\n",
    "        if len(list(apptrain[col].unique())) <= 2:\n",
    "            #train on the training data\n",
    "            le.fit(apptrain[col])\n",
    "            #transform both training and testing data\n",
    "            apptrain[col] = le.transform(apptrain[col])\n",
    "            apptest[col] = le.transform(apptest[col])\n",
    "            \n",
    "            le_count += 1\n",
    "            \n",
    "\n",
    "            \n",
    "#One-Hot encoding\n",
    "apptrain = pd.get_dummies(apptrain)\n",
    "apptest = pd.get_dummies(apptest)\n",
    "\n",
    "\n",
    "\n",
    "print('Training features shape: {}'.format(apptrain.shape))\n",
    "print('Training features shape: {}'.format(apptest.shape))\n",
    "print('{} columns were label encoded'.format(le_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 240)\n",
      "Testing features shape:  (48744, 239)\n",
      "We're back on track, remember the training dataset will have one column more since it DOES have the targets\n"
     ]
    }
   ],
   "source": [
    "# Take the labels out of the training dataset as an inner merge will erase them since the test dataset does not have the targets\n",
    "train_labels = apptrain['TARGET']\n",
    "\n",
    "\n",
    "#aligning the training and testing data, keep only columns present in both df's\n",
    "apptrain, apptest = apptrain.align(apptest, join = 'inner', axis = 1)\n",
    "apptrain['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', apptrain.shape)\n",
    "print('Testing features shape: ', apptest.shape)\n",
    "print(\"We're back on track, remember the training dataset will have one column more since it DOES have the targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (307511, 239)\n",
      "testing data shape (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "# Extra Dependencies\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Creating base df's for machine learning model\n",
    "training_data = apptrain.drop(columns = ['TARGET'])\n",
    "testing_data = apptest.copy()\n",
    "\n",
    "# In the dataframes we still have missing values, WE USE IMPUTATION HERE\n",
    "imputer = Imputer(strategy = 'median')\n",
    "imputer.fit(training_data)\n",
    "imputer.fit(testing_data)\n",
    "training_data = imputer.transform(training_data)\n",
    "testing_data = imputer.transform(testing_data)\n",
    "\n",
    "\n",
    "# We scale our data\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(training_data)\n",
    "training_data_scaled = scaler.transform(training_data)\n",
    "testing_data_scaled = scaler.transform(testing_data)\n",
    "\n",
    "\n",
    "print('training data shape', training_data_scaled.shape)\n",
    "print('testing data shape', testing_data_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION MODEL (BASE FEATURES)\n",
    "The data is ready to be sent into the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ritter\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Develop model with parameters\n",
    "logistic_regression = LogisticRegression(C=0.0001, verbose=2, n_jobs=-1)\n",
    "\n",
    "#train the model by giving it the data\n",
    "logistic_regression.fit(training_data_scaled, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_predictions = logistic_regression.predict_proba(testing_data_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make a function that'll format and save our predictions for submissions to the Kaggle competition\n",
    "def format_and_submit(predictions, desired_file_name):\n",
    "    submit = apptest[['SK_ID_CURR']]\n",
    "    submit['TARGET'] = predictions\n",
    "    submit.to_csv('../Model_Predictions/{}.csv'.format(desired_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ritter\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "format_and_submit(logistic_regression_predictions, \"Logistic_Regression_Untuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using manually engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
